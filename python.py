import streamlit as st
import requests
import json
import io
import math
import numpy as np
import pandas as pd
from docx import Document
import time
from typing import Dict, Any, List

# --- C·∫•u h√¨nh Firebase & LLM API (MANDATORY BOILERPLATE) ---
# S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng Canvas
try:
    API_KEY = "" # S·∫Ω ƒë∆∞·ª£c cung c·∫•p t·ª± ƒë·ªông khi ch·∫°y trong m√¥i tr∆∞·ªùng Canvas
    APP_ID = __app_id
    FIREBASE_CONFIG = json.loads(__firebase_config)
    INITIAL_AUTH_TOKEN = __initial_auth_token
except NameError:
    API_KEY = ""
    APP_ID = "default-app-id"
    FIREBASE_CONFIG = {}
    INITIAL_AUTH_TOKEN = ""

GEMINI_MODEL_FLASH = "gemini-2.5-flash-preview-05-20"
API_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models"

# --- HELPER FUNCTIONS ---

def format_currency(amount: float) -> str:
    """ƒê·ªãnh d·∫°ng ti·ªÅn t·ªá sang t·ª∑ VND"""
    if math.isnan(amount):
        return "N/A"
        
    abs_amount = abs(amount)
    
    if abs_amount >= 1e9:
        return f"{amount / 1e9:,.2f} t·ª∑ VND"
    elif abs_amount >= 1e6:
        return f"{amount / 1e6:,.2f} tri·ªáu VND"
    return f"{amount:,.0f} VND"

def read_docx(uploaded_file: st.runtime.uploaded_file_manager.UploadedFile) -> str:
    """ƒê·ªçc to√†n b·ªô n·ªôi dung vƒÉn b·∫£n t·ª´ file Word ƒë√£ t·∫£i l√™n."""
    try:
        # S·ª≠ d·ª•ng io.BytesIO ƒë·ªÉ ƒë·ªçc file trong b·ªô nh·ªõ
        document = Document(io.BytesIO(uploaded_file.getvalue()))
        text = []
        for paragraph in document.paragraphs:
            text.append(paragraph.text)
        return "\n".join(text)
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file Word: {e}")
        return ""

def clean_and_convert_to_float(value: str) -> float:
    """L√†m s·∫°ch chu·ªói v√† chuy·ªÉn th√†nh float. X·ª≠ l√Ω c√°c ƒë∆°n v·ªã 't·ª∑', 'tri·ªáu', '%'."""
    if not value:
        return 0.0
    
    # Chu·∫©n h√≥a ƒë∆°n v·ªã v√† h·ªá s·ªë nh√¢n
    multiplier = 1.0
    if 't·ª∑' in value.lower() or 'ty' in value.lower() or 'b' in value.lower():
        multiplier = 1e9
    elif 'tri·ªáu' in value.lower() or 'tr' in value.lower() or 'm' in value.lower():
        multiplier = 1e6
        
    is_percentage = '%' in value

    # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë∆°n v·ªã v√† k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt
    cleaned = value.lower().replace('%', '').replace('vnd', '').replace('t·ª∑', '').replace('ty', '').replace('tr', '').replace('m', '').replace('b', '').strip()
    
    # X·ª≠ l√Ω ƒë·ªãnh d·∫°ng th·∫≠p ph√¢n (x√≥a t·∫•t c·∫£ d·∫•u ch·∫•m/ph·∫©y tr·ª´ d·∫•u cu·ªëi c√πng l√†m th·∫≠p ph√¢n)
    if cleaned.count('.') > 1 and cleaned.count(',') == 0: # V√≠ d·ª•: 10.000.000
        cleaned = cleaned.replace('.', '')
    elif cleaned.count(',') > 1 and cleaned.count('.') == 0: # V√≠ d·ª•: 10,000,000
        cleaned = cleaned.replace(',', '')
    
    cleaned = cleaned.replace(',', '.') # Chu·∫©n h√≥a d·∫•u ph·∫©y th√†nh d·∫•u ch·∫•m
    
    try:
        result = float(cleaned) * multiplier
        
        # N·∫øu l√† t·ª∑ l·ªá (WACC, Thu·∫ø), chia cho 100 n·∫øu n√≥ ƒë∆∞·ª£c tr√≠ch xu·∫•t d∆∞·ªõi d·∫°ng s·ªë nguy√™n l·ªõn (v√≠ d·ª•: 20 thay v√¨ 0.2)
        if is_percentage and result > 1:
            return result / 100.0
            
        return result
    except ValueError:
        return 0.0

def call_gemini_api(prompt: str, system_instruction: str, is_json: bool, schema: Dict[str, Any] = None) -> Any:
    """G·ªçi API Gemini v·ªõi ch√≠nh s√°ch exponential backoff."""
    url = f"{API_BASE_URL}/{GEMINI_MODEL_FLASH}:generateContent?key={API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    payload: Dict[str, Any] = {
        "contents": [{"parts": [{"text": prompt}]}],
        "config": {
            "temperature": 0.1,
            # TƒÉng c∆∞·ªùng kh·∫£ nƒÉng tr√≠ch xu·∫•t ch√≠nh x√°c h∆°n
            "systemInstruction": system_instruction 
        }
    }

    if is_json and schema:
        payload["config"]["responseMimeType"] = "application/json"
        payload["config"]["responseSchema"] = schema
        
    MAX_RETRIES = 5
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            response.raise_for_status() 
            result = response.json()
            
            if result and result.get('candidates') and result['candidates'][0].get('content'):
                text = result['candidates'][0]['content']['parts'][0]['text']
                if is_json:
                    # R·∫•t quan tr·ªçng: X·ª≠ l√Ω l·ªói JSON Decode n·∫øu AI tr·∫£ v·ªÅ chu·ªói text
                    try:
                        return json.loads(text)
                    except json.JSONDecodeError:
                        st.error(f"L·ªói gi·∫£i m√£ JSON. AI ƒë√£ tr·∫£ v·ªÅ vƒÉn b·∫£n kh√¥ng ph·∫£i JSON: {text[:100]}...")
                        return None
                return text
            else:
                st.error(f"L·ªói: AI tr·∫£ v·ªÅ kh√¥ng c√≥ n·ªôi dung. Ph·∫£n h·ªìi: {result}")
                return None

        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                wait_time = 2 ** attempt
                time.sleep(wait_time)
            else:
                st.error(f"L·ªói g·ªçi API Gemini sau {MAX_RETRIES} l·∫ßn th·ª≠: {e}")
                return None
        except Exception as e:
            st.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi g·ªçi API: {e}")
            return None
    return None

def extract_financial_data(doc_text: str) -> Dict[str, float]:
    """S·ª≠ d·ª•ng AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh t·ª´ vƒÉn b·∫£n."""
    
    extraction_schema = {
        "type": "OBJECT",
        "properties": {
            "V·ªën_ƒë·∫ßu_t∆∞": {"type": "STRING", "description": "Gi√° tr·ªã v·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu, bao g·ªìm c·∫£ ƒë∆°n v·ªã (v√≠ d·ª•: 30 t·ª∑ VND)"},
            "V√≤ng_ƒë·ªùi_d·ª±_√°n": {"type": "STRING", "description": "S·ªë nƒÉm v√≤ng ƒë·ªùi d·ª± √°n (v√≠ d·ª•: 10 nƒÉm)"},
            "Doanh_thu": {"type": "STRING", "description": "Doanh thu h√†ng nƒÉm (v√≠ d·ª•: 3.5 t·ª∑)"},
            "Chi_ph√≠": {"type": "STRING", "description": "Chi ph√≠ ho·∫°t ƒë·ªông h√†ng nƒÉm (v√≠ d·ª•: 2 t·ª∑)"},
            "WACC": {"type": "STRING", "description": "T·ª∑ l·ªá WACC c·ªßa doanh nghi·ªáp (v√≠ d·ª•: 13%)"},
            "Thu·∫ø": {"type": "STRING", "description": "Thu·∫ø su·∫•t TNDN (v√≠ d·ª•: 20%)"}
        }
    }
    
    system_prompt = (
        "B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh. H√£y tr√≠ch xu·∫•t c√°c th√¥ng s·ªë t√†i ch√≠nh ch√≠nh x√°c "
        "t·ª´ vƒÉn b·∫£n d·ª± √°n kinh doanh ƒë∆∞·ª£c cung c·∫•p, bao g·ªìm c·∫£ ƒë∆°n v·ªã (n·∫øu c√≥). "
        "ƒê·∫£m b·∫£o k·∫øt qu·∫£ tr·∫£ v·ªÅ l√† m·ªôt ƒë·ªëi t∆∞·ª£ng JSON tu√¢n th·ªß schema ƒë√£ cho. "
        "Gi·∫£ ƒë·ªãnh d·ª± √°n c√≥ d√≤ng ti·ªÅn ƒë·ªÅu h√†ng nƒÉm. Ch·ªâ tr·∫£ v·ªÅ JSON."
    )
    
    prompt = f"Tr√≠ch xu·∫•t c√°c th√¥ng s·ªë t√†i ch√≠nh t·ª´ vƒÉn b·∫£n sau:\n\n---\n{doc_text}\n---"
    
    raw_data = None
    with st.spinner("1. AI ƒëang tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh..."):
        raw_data = call_gemini_api(prompt, system_prompt, is_json=True, schema=extraction_schema)

    if raw_data and isinstance(raw_data, dict):
        # Chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã th√¥ ƒë√£ tr√≠ch xu·∫•t sang ƒë·ªãnh d·∫°ng s·ªë
        processed_data = {
            'I0': clean_and_convert_to_float(raw_data.get('V·ªën_ƒë·∫ßu_t∆∞', '0')),
            'N': int(clean_and_convert_to_float(raw_data.get('V√≤ng_ƒë·ªùi_d·ª±_√°n', '0'))),
            'R': clean_and_convert_to_float(raw_data.get('Doanh_thu', '0')),
            'C': clean_and_convert_to_float(raw_data.get('Chi_ph√≠', '0')),
            'WACC': clean_and_convert_to_float(raw_data.get('WACC', '0')), 
            'Tax': clean_and_convert_to_float(raw_data.get('Thu·∫ø', '0'))
        }
        
        # ƒê·∫£m b·∫£o WACC v√† Tax ·ªü d·∫°ng th·∫≠p ph√¢n (v√≠ d·ª•: 0.13 v√† 0.2)
        if processed_data['WACC'] > 1.0: processed_data['WACC'] /= 100.0
        if processed_data['Tax'] > 1.0: processed_data['Tax'] /= 100.0

        return processed_data
    return {}

@st.cache_data(show_spinner=False)
def calculate_financial_metrics(data: Dict[str, float]) -> Dict[str, Any]:
    """T√≠nh to√°n c√°c ch·ªâ s·ªë NPV, IRR, PP, DPP."""
    I0 = data.get('I0', 0)
    N = int(data.get('N', 0))
    R = data.get('R', 0)
    C = data.get('C', 0)
    WACC = data.get('WACC', 0.1) 
    Tax = data.get('Tax', 0.2)
    
    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o c∆° b·∫£n
    if N <= 0 or I0 <= 0:
        return {"NPV": np.nan, "IRR": np.nan, "PP": np.nan, "DPP": np.nan, "CF_Table": []}
    
    # 1. T√≠nh D√≤ng ti·ªÅn thu·∫ßn h√†ng nƒÉm (NCF)
    PBT = R - C
    PAT = PBT * (1 - Tax)
    NCF = PAT # D√≤ng ti·ªÅn thu·∫ßn h√†ng nƒÉm (Gi·∫£ ƒë·ªãnh NCF ƒë·ªÅu h√†ng nƒÉm v√† kh√¥ng c√≥ Kh·∫•u hao)
    data['NCF'] = NCF # C·∫≠p nh·∫≠t NCF v√†o dict g·ªëc

    # Ki·ªÉm tra NCF ƒë·ªÉ tr√°nh chia cho 0
    if NCF <= 0 and I0 > 0:
        return {"NPV": -I0, "IRR": np.nan, "PP": np.nan, "DPP": np.nan, "CF_Table": []}

    # B·∫£ng D√≤ng ti·ªÅn
    cf_data = []
    cf_data.append({"NƒÉm": 0, "NCF": -I0, "PV_NCF": -I0, "CF_Cum": -I0, "PV_CF_Cum": -I0})

    CF_Cum = -I0
    PV_CF_Cum = -I0
    
    # T√≠nh to√°n cho c√°c nƒÉm 1 ƒë·∫øn N
    for t in range(1, N + 1):
        # Gi√° tr·ªã hi·ªán t·∫°i c·ªßa NCF
        PV_NCF = NCF / (1 + WACC) ** t
        
        # D√≤ng ti·ªÅn t√≠ch l≈©y v√† d√≤ng ti·ªÅn t√≠ch l≈©y chi·∫øt kh·∫•u
        CF_Cum += NCF
        PV_CF_Cum += PV_NCF
        
        cf_data.append({
            "NƒÉm": t, 
            "NCF": NCF, 
            "PV_NCF": PV_NCF, 
            "CF_Cum": CF_Cum, 
            "PV_CF_Cum": PV_CF_Cum
        })
        
    cf_df = pd.DataFrame(cf_data)
    
    # 2. NPV (Gi√° tr·ªã hi·ªán t·∫°i thu·∫ßn)
    NPV = cf_df['PV_NCF'].sum()
    
    # 3. IRR (T·ª∑ su·∫•t sinh l·ªùi n·ªôi b·ªô)
    cash_flows = np.array([-I0] + [NCF] * N)
    try:
        IRR = np.irr(cash_flows)
    except ValueError:
        IRR = np.nan
        
    # 4. PP (Th·ªùi gian ho√†n v·ªën) v√† 5. DPP (Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u)
    PP = np.nan
    DPP = np.nan
    
    # T√≠nh PP t·ª´ CF_Cum
    pp_row_idx = cf_df[cf_df['CF_Cum'] >= 0].index
    if len(pp_row_idx) > 0 and pp_row_idx[0] > 0:
        k = pp_row_idx[0] 
        CF_k_minus_1 = cf_df.loc[k-1, 'CF_Cum']
        
        # Ch·ªâ t√≠nh n·∫øu NCF > 0 ƒë·ªÉ tr√°nh l·ªói chia cho 0
        if NCF > 0:
             PP = (k - 1) + abs(CF_k_minus_1) / NCF
    
    # T√≠nh DPP t·ª´ PV_CF_Cum
    dpp_row_idx = cf_df[cf_df['PV_CF_Cum'] >= 0].index
    if len(dpp_row_idx) > 0 and dpp_row_idx[0] > 0:
        k_dpp = dpp_row_idx[0] 
        PV_CF_k_minus_1 = cf_df.loc[k_dpp-1, 'PV_CF_Cum'] 
        PV_NCF_k = cf_df.loc[k_dpp, 'PV_NCF'] 
        
        # Ch·ªâ t√≠nh n·∫øu PV_NCF_k > 0
        if PV_NCF_k > 0:
            DPP = (k_dpp - 1) + abs(PV_CF_k_minus_1) / PV_NCF_k
        
    
    return {
        "NPV": NPV, 
        "IRR": IRR, 
        "PP": PP, 
        "DPP": DPP,
        "CF_Table": cf_df
    }

def get_ai_analysis_report(metrics: Dict[str, Any], initial_data: Dict[str, float]) -> str:
    """Y√™u c·∫ßu AI ph√¢n t√≠ch chuy√™n s√¢u c√°c ch·ªâ s·ªë t√†i ch√≠nh."""
    
    NPV = metrics.get('NPV', np.nan)
    IRR = metrics.get('IRR', np.nan)
    PP = metrics.get('PP', np.nan)
    DPP = metrics.get('DPP', np.nan)
    WACC = initial_data.get('WACC', 0.1) * 100
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu cho AI
    data_for_ai = (
        f"NPV (Gi√° tr·ªã hi·ªán t·∫°i thu·∫ßn): {format_currency(NPV)}\n"
        f"IRR (T·ª∑ su·∫•t sinh l·ªùi n·ªôi b·ªô): {IRR*100:.2f}% (WACC c·ªßa doanh nghi·ªáp l√† {WACC:.2f}%)\n"
        f"PP (Th·ªùi gian ho√†n v·ªën): {PP:.2f} nƒÉm\n"
        f"DPP (Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u): {DPP:.2f} nƒÉm\n"
        f"V·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu: {format_currency(initial_data.get('I0'))}\n"
        f"V√≤ng ƒë·ªùi d·ª± √°n: {initial_data.get('N')} nƒÉm\n"
        f"D√≤ng ti·ªÅn thu·∫ßn (NCF) h√†ng nƒÉm: {format_currency(initial_data.get('NCF'))}\n"
    )
    
    # Th√™m ƒëi·ªÅu ki·ªán ƒë·ªÉ AI ƒë∆∞a ra quy·∫øt ƒë·ªãnh ch·∫•p nh·∫≠n/t·ª´ ch·ªëi r√µ r√†ng h∆°n
    if not math.isnan(NPV) and NPV > 0 and not math.isnan(IRR) and IRR > WACC/100:
        feasibility_status = "D·ª± √°n c√≥ kh·∫£ nƒÉng ch·∫•p nh·∫≠n (NPV > 0 v√† IRR > WACC)."
    elif not math.isnan(NPV) and NPV < 0:
        feasibility_status = "D·ª± √°n c√≥ kh·∫£ nƒÉng b·ªã t·ª´ ch·ªëi (NPV < 0)."
    else:
        feasibility_status = "D·ªØ li·ªáu kh√¥ng ƒë·ªß ho·∫∑c d·ª± √°n bi√™n ƒë·ªô th·∫•p (c·∫ßn ph√¢n t√≠ch s√¢u)."

    system_prompt = (
        "B·∫°n l√† m·ªôt chuy√™n gia th·∫©m ƒë·ªãnh v√† ph√¢n t√≠ch d·ª± √°n ƒë·∫ßu t∆∞. "
        "D·ª±a tr√™n c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ t√†i ch√≠nh ƒë∆∞·ª£c cung c·∫•p, h√£y ƒë∆∞a ra b√°o c√°o ph√¢n t√≠ch chuy√™n s√¢u (√≠t nh·∫•t 3 ƒëo·∫°n):"
        "1. ƒê√°nh gi√° t√≠nh kh·∫£ thi v√† ch·∫•p nh·∫≠n/t·ª´ ch·ªëi d·ª± √°n (d·ª±a v√†o NPV v√† so s√°nh IRR v·ªõi WACC)."
        "2. Nh·∫≠n x√©t v·ªÅ r·ªßi ro v√† t√≠nh thanh kho·∫£n c·ªßa d·ª± √°n (d·ª±a v√†o PP v√† DPP)."
        "3. ƒê·ªÅ xu·∫•t ki·∫øn ngh·ªã ƒë·ªÉ c·∫£i thi·ªán hi·ªáu qu·∫£ t√†i ch√≠nh (v√≠ d·ª•: gi·∫£m v·ªën, tƒÉng doanh thu, k√©o d√†i v√≤ng ƒë·ªùi). "
        "Vi·∫øt b·∫±ng ti·∫øng Vi·ªát v√† s·ª≠ d·ª•ng ng√¥n ng·ªØ chuy√™n nghi·ªáp."
    )
    
    prompt = (
        f"Ph√¢n t√≠ch b√°o c√°o hi·ªáu qu·∫£ t√†i ch√≠nh d·ª± √°n v·ªõi c√°c ch·ªâ s·ªë sau:\n\n---\n{data_for_ai}\n---"
        f"H√£y b·∫Øt ƒë·∫ßu b√°o c√°o b·∫±ng vi·ªác kh·∫≥ng ƒë·ªãnh tr·∫°ng th√°i d·ª± √°n: {feasibility_status}"
    )
    
    with st.spinner("4. AI ƒëang t·∫°o b√°o c√°o ph√¢n t√≠ch chuy√™n s√¢u..."):
        analysis_report = call_gemini_api(prompt, system_prompt, is_json=False)
        return analysis_report


# --- STREAMLIT APP ---
st.set_page_config(
    page_title="App Ph√¢n T√≠ch D·ª± √Ån ƒê·∫ßu T∆∞ (Word to Metrics)",
    layout="wide"
)

st.title("üí∞ Ph√¢n T√≠ch Hi·ªáu Qu·∫£ D·ª± √Ån ƒê·∫ßu T∆∞ T·ª± ƒê·ªông")
st.markdown("S·ª≠ d·ª•ng AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ file Word v√† t√≠nh to√°n c√°c ch·ªâ s·ªë NPV, IRR, PP, DPP.")

# --- Session State Initialization ---
if 'project_data' not in st.session_state:
    st.session_state.project_data = {}
if 'metrics' not in st.session_state:
    st.session_state.metrics = {}
if 'doc_text' not in st.session_state:
    st.session_state.doc_text = ""

# --- 1. T·∫£i File v√† L·ªçc D·ªØ li·ªáu ---
uploaded_file = st.file_uploader(
    "T·∫£i l√™n file Word (.docx) ch·ª©a ph∆∞∆°ng √°n kinh doanh",
    type=['docx']
)

if uploaded_file is not None:
    st.session_state.doc_text = read_docx(uploaded_file)
    
    if st.button("1. L·ªçc D·ªØ li·ªáu T√†i ch√≠nh (AI)"):
        if st.session_state.doc_text:
            st.session_state.project_data = extract_financial_data(st.session_state.doc_text)
            st.session_state.metrics = {} # Reset metrics khi l·ªçc l·∫°i

    if st.session_state.project_data and st.session_state.project_data.get('I0', 0) > 0:
        
        data = st.session_state.project_data
        
        st.subheader("‚úÖ D·ªØ li·ªáu D·ª± √°n ƒë√£ L·ªçc")
        col1, col2, col3 = st.columns(3)
        col4, col5, col6 = st.columns(3)

        # T√≠nh to√°n NCF ƒë·ªÉ hi·ªÉn th·ªã
        PBT = data.get('R', 0) - data.get('C', 0)
        PAT = PBT * (1 - data.get('Tax', 0.2))
        NCF = PAT
        st.session_state.project_data['NCF'] = NCF # L∆∞u NCF v√†o state

        col1.metric("V·ªën ƒê·∫ßu t∆∞ ($I_0$)", format_currency(data.get('I0')))
        col2.metric("V√≤ng ƒë·ªùi D·ª± √°n ($N$)", f"{data.get('N')} nƒÉm")
        col3.metric("WACC", f"{data.get('WACC', 0.0) * 100:.2f}%")
        col4.metric("Doanh thu ($R$)", format_currency(data.get('R')))
        col5.metric("Chi ph√≠ ($C$)", format_currency(data.get('C')))
        col6.metric("Thu·∫ø su·∫•t", f"{data.get('Tax', 0.0) * 100:.0f}%")
        
        st.metric("D√≤ng ti·ªÅn thu·∫ßn (NCF) h√†ng nƒÉm", format_currency(NCF))
        st.markdown("---")
        
        # --- 2. X√¢y d·ª±ng B·∫£ng D√≤ng ti·ªÅn v√† 3. T√≠nh Ch·ªâ s·ªë ---
        st.subheader("2 & 3. B·∫£ng D√≤ng ti·ªÅn v√† Ch·ªâ s·ªë ƒê√°nh gi√° Hi·ªáu qu·∫£")
        
        if st.button("T√≠nh to√°n Ch·ªâ s·ªë T√†i ch√≠nh (NPV, IRR, PP, DPP)"):
            st.session_state.metrics = calculate_financial_metrics(st.session_state.project_data)
            
        # Ki·ªÉm tra n·∫øu t√≠nh to√°n ƒë√£ ƒë∆∞·ª£c th·ª±c hi·ªán v√† th√†nh c√¥ng
        if st.session_state.metrics and st.session_state.metrics.get("CF_Table") is not None and not st.session_state.metrics.get("CF_Table").empty:
            metrics = st.session_state.metrics
            
            # Hi·ªÉn th·ªã Ch·ªâ s·ªë ƒê√°nh gi√°
            col_m1, col_m2, col_m3, col_m4 = st.columns(4)
            
            col_m1.metric("NPV (Gi√° tr·ªã hi·ªán t·∫°i thu·∫ßn)", format_currency(metrics['NPV']))
            col_m2.metric("IRR (T·ª∑ su·∫•t sinh l·ªùi n·ªôi b·ªô)", f"{metrics['IRR'] * 100:.2f}%" if not math.isnan(metrics['IRR']) else "N/A")
            col_m3.metric("PP (Ho√†n v·ªën)", f"{metrics['PP']:.2f} nƒÉm" if not math.isnan(metrics['PP']) else "N/A")
            col_m4.metric("DPP (Ho√†n v·ªën chi·∫øt kh·∫•u)", f"{metrics['DPP']:.2f} nƒÉm" if not math.isnan(metrics['DPP']) else "N/A")

            st.markdown("#### B·∫£ng D√≤ng ti·ªÅn D·ª± √°n")
            cf_df = metrics['CF_Table'].copy()
            
            # ƒê·ªãnh d·∫°ng DataFrame ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp h∆°n
            cf_df['NƒÉm'] = cf_df['NƒÉm'].astype(int)
            st.dataframe(
                cf_df.style.format({
                    'NCF': lambda x: format_currency(x),
                    'PV_NCF': lambda x: format_currency(x),
                    'CF_Cum': lambda x: format_currency(x),
                    'PV_CF_Cum': lambda x: format_currency(x),
                }),
                use_container_width=True,
                hide_index=True
            )
            st.markdown("---")
            
            # --- 4. Y√™u c·∫ßu AI Ph√¢n t√≠ch ---
            st.subheader("4. B√°o c√°o Ph√¢n t√≠ch Chuy√™n s√¢u (AI)")
            
            if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch Hi·ªáu qu·∫£ D·ª± √°n"):
                report = get_ai_analysis_report(metrics, st.session_state.project_data)
                st.markdown("#### K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI")
                st.info(report)
        
        else:
             st.info("Nh·∫•n n√∫t 'T√≠nh to√°n Ch·ªâ s·ªë T√†i ch√≠nh' ƒë·ªÉ t·∫°o b·∫£ng d√≤ng ti·ªÅn v√† c√°c ch·ªâ s·ªë.")

    else:
        if uploaded_file and st.session_state.doc_text and not st.session_state.project_data:
             st.warning("Vui l√≤ng nh·∫•n n√∫t 'L·ªçc D·ªØ li·ªáu T√†i ch√≠nh (AI)' ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng s·ªë.")
        elif uploaded_file and st.session_state.project_data and st.session_state.project_data.get('I0', 0) <= 0:
             st.error("Kh√¥ng th·ªÉ t√≠nh to√°n: V·ªën ƒê·∫ßu t∆∞ ($I_0$) ho·∫∑c V√≤ng ƒë·ªùi D·ª± √°n ($N$) ƒë∆∞·ª£c tr√≠ch xu·∫•t b·∫±ng 0 ho·∫∑c kh√¥ng ph·∫£i s·ªë d∆∞∆°ng.")

else:
    st.info("Vui l√≤ng t·∫£i l√™n file Word ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
