import streamlit as st
import requests
import json
import io
import math
import numpy as np
import pandas as pd
from docx import Document
import time
from typing import Dict, Any, List

# --- C·∫•u h√¨nh Firebase & LLM API (MANDATORY BOILERPLATE) ---
# S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng Canvas
try:
    API_KEY = "" # S·∫Ω ƒë∆∞·ª£c cung c·∫•p t·ª± ƒë·ªông khi ch·∫°y trong m√¥i tr∆∞·ªùng Canvas
    APP_ID = __app_id
    FIREBASE_CONFIG = json.loads(__firebase_config)
    INITIAL_AUTH_TOKEN = __initial_auth_token
except NameError:
    API_KEY = ""
    APP_ID = "default-app-id"
    FIREBASE_CONFIG = {}
    INITIAL_AUTH_TOKEN = ""

GEMINI_MODEL_FLASH = "gemini-2.5-flash-preview-05-20"
API_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models"

# --- HELPER FUNCTIONS ---

def format_currency(amount: float) -> str:
    """ƒê·ªãnh d·∫°ng ti·ªÅn t·ªá sang t·ª∑ VND"""
    if abs(amount) >= 1e9:
        return f"{amount / 1e9:,.2f} t·ª∑ VND"
    elif abs(amount) >= 1e6:
        return f"{amount / 1e6:,.2f} tri·ªáu VND"
    return f"{amount:,.0f} VND"

def read_docx(uploaded_file: st.runtime.uploaded_file_manager.UploadedFile) -> str:
    """ƒê·ªçc to√†n b·ªô n·ªôi dung vƒÉn b·∫£n t·ª´ file Word ƒë√£ t·∫£i l√™n."""
    try:
        # S·ª≠ d·ª•ng io.BytesIO ƒë·ªÉ ƒë·ªçc file trong b·ªô nh·ªõ
        document = Document(io.BytesIO(uploaded_file.getvalue()))
        text = []
        for paragraph in document.paragraphs:
            text.append(paragraph.text)
        return "\n".join(text)
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file Word: {e}")
        return ""

def clean_and_convert_to_float(value: str) -> float:
    """L√†m s·∫°ch chu·ªói (x√≥a ƒë∆°n v·ªã, k√Ω t·ª± kh√¥ng ph·∫£i s·ªë/d·∫•u ph·∫©y/d·∫•u ch·∫•m) v√† chuy·ªÉn th√†nh float."""
    if not value:
        return 0.0
    
    # Chu·∫©n h√≥a ƒë∆°n v·ªã
    multiplier = 1.0
    if 't·ª∑' in value.lower() or 'ty' in value.lower() or 'b' in value.lower():
        multiplier = 1e9
    elif 'tri·ªáu' in value.lower() or 'tr' in value.lower() or 'm' in value.lower():
        multiplier = 1e6
    
    # Lo·∫°i b·ªè k√Ω t·ª± kh√¥ng ph·∫£i s·ªë, d·∫•u ph·∫©y, d·∫•u ch·∫•m, v√† k√Ω t·ª± ƒë∆°n v·ªã.
    cleaned = value.lower().replace('%', '').replace('vnd', '').replace('t·ª∑', '').replace('ty', '').replace('tr', '').replace('m', '').replace('b', '').strip()
    
    # X·ª≠ l√Ω ƒë·ªãnh d·∫°ng th·∫≠p ph√¢n (d√πng d·∫•u ph·∫©y ho·∫∑c d·∫•u ch·∫•m)
    cleaned = cleaned.replace('.', '').replace(',', '.') # Gi·ªØ l·∫°i d·∫•u ch·∫•m cu·ªëi c√πng l√†m th·∫≠p ph√¢n

    try:
        return float(cleaned) * multiplier
    except ValueError:
        return 0.0

def call_gemini_api(prompt: str, system_instruction: str, is_json: bool, schema: Dict[str, Any] = None) -> Any:
    """G·ªçi API Gemini v·ªõi ch√≠nh s√°ch exponential backoff."""
    url = f"{API_BASE_URL}/{GEMINI_MODEL_FLASH}:generateContent?key={API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    payload: Dict[str, Any] = {
        "contents": [{"parts": [{"text": prompt}]}],
        "systemInstruction": {"parts": [{"text": system_instruction}]},
        "config": {
            "temperature": 0.1,
        }
    }

    if is_json and schema:
        payload["config"]["responseMimeType"] = "application/json"
        payload["config"]["responseSchema"] = schema
        
    MAX_RETRIES = 5
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            response.raise_for_status() 
            result = response.json()
            
            if result and result.get('candidates') and result['candidates'][0].get('content'):
                text = result['candidates'][0]['content']['parts'][0]['text']
                if is_json:
                    return json.loads(text)
                return text
            else:
                st.error(f"L·ªói: AI tr·∫£ v·ªÅ kh√¥ng c√≥ n·ªôi dung. Ph·∫£n h·ªìi: {result}")
                return None

        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                wait_time = 2 ** attempt
                time.sleep(wait_time)
            else:
                st.error(f"L·ªói g·ªçi API Gemini sau {MAX_RETRIES} l·∫ßn th·ª≠: {e}")
                return None
        except json.JSONDecodeError:
            if is_json:
                 st.error("L·ªói gi·∫£i m√£ JSON t·ª´ ph·∫£n h·ªìi AI.")
                 # Th·ª≠ tr·∫£ v·ªÅ text th√¥ n·∫øu JSON decode l·ªói
                 return text 
            return text 
    return None

def extract_financial_data(doc_text: str) -> Dict[str, float]:
    """S·ª≠ d·ª•ng AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh t·ª´ vƒÉn b·∫£n."""
    
    extraction_schema = {
        "type": "OBJECT",
        "properties": {
            "V·ªën_ƒë·∫ßu_t∆∞": {"type": "STRING", "description": "Gi√° tr·ªã v·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu (v√≠ d·ª•: 30 t·ª∑ VND)"},
            "V√≤ng_ƒë·ªùi_d·ª±_√°n": {"type": "STRING", "description": "S·ªë nƒÉm v√≤ng ƒë·ªùi d·ª± √°n (v√≠ d·ª•: 10 nƒÉm)"},
            "Doanh_thu": {"type": "STRING", "description": "Doanh thu h√†ng nƒÉm (v√≠ d·ª•: 3.5 t·ª∑)"},
            "Chi_ph√≠": {"type": "STRING", "description": "Chi ph√≠ ho·∫°t ƒë·ªông h√†ng nƒÉm (v√≠ d·ª•: 2 t·ª∑)"},
            "WACC": {"type": "STRING", "description": "T·ª∑ l·ªá WACC c·ªßa doanh nghi·ªáp (v√≠ d·ª•: 13%)"},
            "Thu·∫ø": {"type": "STRING", "description": "Thu·∫ø su·∫•t TNDN (v√≠ d·ª•: 20%)"}
        }
    }
    
    system_prompt = (
        "B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh. H√£y tr√≠ch xu·∫•t c√°c th√¥ng s·ªë t√†i ch√≠nh ch√≠nh x√°c "
        "t·ª´ vƒÉn b·∫£n d·ª± √°n kinh doanh ƒë∆∞·ª£c cung c·∫•p, bao g·ªìm c·∫£ ƒë∆°n v·ªã (n·∫øu c√≥) v√†o ƒë·ªãnh d·∫°ng JSON. "
        "Gi·∫£ ƒë·ªãnh d·ª± √°n c√≥ d√≤ng ti·ªÅn ƒë·ªÅu h√†ng nƒÉm. Ch·ªâ tr·∫£ v·ªÅ JSON."
    )
    
    prompt = f"Tr√≠ch xu·∫•t c√°c th√¥ng s·ªë t√†i ch√≠nh t·ª´ vƒÉn b·∫£n sau:\n\n---\n{doc_text}\n---"
    
    raw_data = None
    with st.spinner("1. AI ƒëang tr√≠ch xu·∫•t d·ªØ li·ªáu t√†i ch√≠nh..."):
        raw_data = call_gemini_api(prompt, system_prompt, is_json=True, schema=extraction_schema)

    if raw_data and isinstance(raw_data, dict):
        # Chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã th√¥ ƒë√£ tr√≠ch xu·∫•t sang ƒë·ªãnh d·∫°ng s·ªë
        processed_data = {
            'I0': clean_and_convert_to_float(raw_data.get('V·ªën_ƒë·∫ßu_t∆∞', '0')),
            'N': int(clean_and_convert_to_float(raw_data.get('V√≤ng_ƒë·ªùi_d·ª±_√°n', '0'))),
            'R': clean_and_convert_to_float(raw_data.get('Doanh_thu', '0')),
            'C': clean_and_convert_to_float(raw_data.get('Chi_ph√≠', '0')),
            'WACC': clean_and_convert_to_float(raw_data.get('WACC', '0')) / 100, # Chuy·ªÉn % sang th·∫≠p ph√¢n
            'Tax': clean_and_convert_to_float(raw_data.get('Thu·∫ø', '0')) / 100
        }
        return processed_data
    return {}

@st.cache_data(show_spinner=False)
def calculate_financial_metrics(data: Dict[str, float]) -> Dict[str, Any]:
    """T√≠nh to√°n c√°c ch·ªâ s·ªë NPV, IRR, PP, DPP."""
    I0 = data.get('I0', 0)
    N = int(data.get('N', 0))
    R = data.get('R', 0)
    C = data.get('C', 0)
    WACC = data.get('WACC', 0.1) # Default WACC 10%

    if N <= 0 or I0 <= 0:
        return {"NPV": np.nan, "IRR": np.nan, "PP": np.nan, "DPP": np.nan, "CF_Table": []}

    Tax = data.get('Tax', 0.2)
    
    # 1. T√≠nh D√≤ng ti·ªÅn thu·∫ßn h√†ng nƒÉm (NCF)
    # Gi·∫£ ƒë·ªãnh: Kh√¥ng c√≥ kh·∫•u hao, NCF = PAT
    PBT = R - C
    PAT = PBT * (1 - Tax)
    NCF = PAT # D√≤ng ti·ªÅn thu·∫ßn h√†ng nƒÉm

    # B·∫£ng D√≤ng ti·ªÅn
    cf_data = []
    cf_data.append({"NƒÉm": 0, "NCF": -I0, "PV_NCF": -I0, "CF_Cum": -I0, "PV_CF_Cum": -I0})

    CF_Cum = -I0
    PV_CF_Cum = -I0
    
    # T√≠nh to√°n cho c√°c nƒÉm 1 ƒë·∫øn N
    for t in range(1, N + 1):
        # Gi√° tr·ªã hi·ªán t·∫°i c·ªßa NCF
        PV_NCF = NCF / (1 + WACC) ** t
        
        # D√≤ng ti·ªÅn t√≠ch l≈©y v√† d√≤ng ti·ªÅn t√≠ch l≈©y chi·∫øt kh·∫•u
        CF_Cum += NCF
        PV_CF_Cum += PV_NCF
        
        cf_data.append({
            "NƒÉm": t, 
            "NCF": NCF, 
            "PV_NCF": PV_NCF, 
            "CF_Cum": CF_Cum, 
            "PV_CF_Cum": PV_CF_Cum
        })
        
    cf_df = pd.DataFrame(cf_data)
    
    # 2. NPV (Gi√° tr·ªã hi·ªán t·∫°i thu·∫ßn)
    NPV = cf_df['PV_NCF'].sum()
    
    # 3. IRR (T·ª∑ su·∫•t sinh l·ªùi n·ªôi b·ªô)
    # D√≤ng ti·ªÅn cho numpy.irr (nƒÉm 0 l√† -I0, c√°c nƒÉm sau l√† NCF)
    cash_flows = np.array([-I0] + [NCF] * N)
    try:
        IRR = np.irr(cash_flows)
    except ValueError:
        IRR = np.nan # C√≥ th·ªÉ kh√¥ng t√¨m th·∫•y IRR n·∫øu NCF qu√° th·∫•p
        
    # 4. PP (Th·ªùi gian ho√†n v·ªën)
    # Ho√†n v·ªën ƒë·ªÅu
    PP = I0 / NCF if NCF > 0 else np.nan
    
    # 5. DPP (Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u)
    DPP = np.nan
    
    # T√≠nh PP v√† DPP t·ª´ CF_Cum v√† PV_CF_Cum
    
    # T√¨m nƒÉm ho√†n v·ªën PP
    pp_row_idx = cf_df[cf_df['CF_Cum'] >= 0].index
    if len(pp_row_idx) > 0:
        k = pp_row_idx[0] # NƒÉm ho√†n v·ªën ƒë·∫ßu ti√™n (v√≠ d·ª•: nƒÉm 4)
        CF_k_minus_1 = cf_df.loc[k-1, 'CF_Cum'] # D√≤ng ti·ªÅn t√≠ch l≈©y cu·ªëi nƒÉm tr∆∞·ªõc (nƒÉm 3)
        
        # C√¥ng th·ª©c: k - 1 + |CF t√≠ch l≈©y nƒÉm k-1| / NCF nƒÉm k
        PP = (k - 1) + abs(CF_k_minus_1) / NCF
    
    # T√¨m nƒÉm ho√†n v·ªën DPP
    dpp_row_idx = cf_df[cf_df['PV_CF_Cum'] >= 0].index
    if len(dpp_row_idx) > 0:
        k_dpp = dpp_row_idx[0] # NƒÉm ho√†n v·ªën chi·∫øt kh·∫•u ƒë·∫ßu ti√™n
        PV_CF_k_minus_1 = cf_df.loc[k_dpp-1, 'PV_CF_Cum'] # D√≤ng ti·ªÅn chi·∫øt kh·∫•u t√≠ch l≈©y cu·ªëi nƒÉm tr∆∞·ªõc
        PV_NCF_k = cf_df.loc[k_dpp, 'PV_NCF'] # D√≤ng ti·ªÅn chi·∫øt kh·∫•u c·ªßa nƒÉm k
        
        # C√¥ng th·ª©c: k_dpp - 1 + |PV_CF t√≠ch l≈©y nƒÉm k_dpp-1| / PV_NCF nƒÉm k
        DPP = (k_dpp - 1) + abs(PV_CF_k_minus_1) / PV_NCF_k
        
    
    return {
        "NPV": NPV, 
        "IRR": IRR, 
        "PP": PP, 
        "DPP": DPP,
        "CF_Table": cf_df
    }

def get_ai_analysis_report(metrics: Dict[str, Any], initial_data: Dict[str, float]) -> str:
    """Y√™u c·∫ßu AI ph√¢n t√≠ch chuy√™n s√¢u c√°c ch·ªâ s·ªë t√†i ch√≠nh."""
    
    NPV = metrics.get('NPV', np.nan)
    IRR = metrics.get('IRR', np.nan)
    PP = metrics.get('PP', np.nan)
    DPP = metrics.get('DPP', np.nan)
    WACC = initial_data.get('WACC', 0.1) * 100
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu cho AI
    data_for_ai = (
        f"NPV (Gi√° tr·ªã hi·ªán t·∫°i thu·∫ßn): {format_currency(NPV)}\n"
        f"IRR (T·ª∑ su·∫•t sinh l·ªùi n·ªôi b·ªô): {IRR*100:.2f}% (WACC c·ªßa doanh nghi·ªáp l√† {WACC:.2f}%)\n"
        f"PP (Th·ªùi gian ho√†n v·ªën): {PP:.2f} nƒÉm\n"
        f"DPP (Th·ªùi gian ho√†n v·ªën c√≥ chi·∫øt kh·∫•u): {DPP:.2f} nƒÉm\n"
        f"V·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu: {format_currency(initial_data.get('I0'))}\n"
        f"V√≤ng ƒë·ªùi d·ª± √°n: {initial_data.get('N')} nƒÉm\n"
        f"D√≤ng ti·ªÅn thu·∫ßn (NCF) h√†ng nƒÉm: {format_currency(initial_data.get('NCF'))}\n"
    )

    system_prompt = (
        "B·∫°n l√† m·ªôt chuy√™n gia th·∫©m ƒë·ªãnh v√† ph√¢n t√≠ch d·ª± √°n ƒë·∫ßu t∆∞. "
        "D·ª±a tr√™n c√°c ch·ªâ s·ªë hi·ªáu qu·∫£ t√†i ch√≠nh ƒë∆∞·ª£c cung c·∫•p, h√£y ƒë∆∞a ra b√°o c√°o ph√¢n t√≠ch chuy√™n s√¢u (√≠t nh·∫•t 3 ƒëo·∫°n):"
        "1. ƒê√°nh gi√° t√≠nh kh·∫£ thi v√† ch·∫•p nh·∫≠n/t·ª´ ch·ªëi d·ª± √°n (d·ª±a v√†o NPV v√† so s√°nh IRR v·ªõi WACC)."
        "2. Nh·∫≠n x√©t v·ªÅ r·ªßi ro v√† t√≠nh thanh kho·∫£n c·ªßa d·ª± √°n (d·ª±a v√†o PP v√† DPP)."
        "3. ƒê·ªÅ xu·∫•t ki·∫øn ngh·ªã ƒë·ªÉ c·∫£i thi·ªán hi·ªáu qu·∫£ t√†i ch√≠nh (v√≠ d·ª•: gi·∫£m v·ªën, tƒÉng doanh thu, k√©o d√†i v√≤ng ƒë·ªùi). "
        "Vi·∫øt b·∫±ng ti·∫øng Vi·ªát v√† s·ª≠ d·ª•ng ng√¥n ng·ªØ chuy√™n nghi·ªáp."
    )
    
    prompt = f"Ph√¢n t√≠ch b√°o c√°o hi·ªáu qu·∫£ t√†i ch√≠nh d·ª± √°n v·ªõi c√°c ch·ªâ s·ªë sau:\n\n---\n{data_for_ai}\n---"
    
    with st.spinner("4. AI ƒëang t·∫°o b√°o c√°o ph√¢n t√≠ch chuy√™n s√¢u..."):
        analysis_report = call_gemini_api(prompt, system_prompt, is_json=False)
        return analysis_report


# --- STREAMLIT APP ---
st.set_page_config(
    page_title="App Ph√¢n T√≠ch D·ª± √Ån ƒê·∫ßu T∆∞ (Word to Metrics)",
    layout="wide"
)

st.title("üí∞ Ph√¢n T√≠ch Hi·ªáu Qu·∫£ D·ª± √Ån ƒê·∫ßu T∆∞ T·ª± ƒê·ªông")
st.markdown("S·ª≠ d·ª•ng AI ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ file Word v√† t√≠nh to√°n c√°c ch·ªâ s·ªë NPV, IRR, PP, DPP.")

# --- 1. T·∫£i File v√† L·ªçc D·ªØ li·ªáu ---
uploaded_file = st.file_uploader(
    "T·∫£i l√™n file Word (.docx) ch·ª©a ph∆∞∆°ng √°n kinh doanh",
    type=['docx']
)

if 'project_data' not in st.session_state:
    st.session_state.project_data = {}
if 'metrics' not in st.session_state:
    st.session_state.metrics = {}
if 'doc_text' not in st.session_state:
    st.session_state.doc_text = ""

if uploaded_file is not None:
    st.session_state.doc_text = read_docx(uploaded_file)
    
    if st.button("1. L·ªçc D·ªØ li·ªáu T√†i ch√≠nh (AI)"):
        if st.session_state.doc_text:
            st.session_state.project_data = extract_financial_data(st.session_state.doc_text)
            st.session_state.metrics = {} # Reset metrics khi l·ªçc l·∫°i

    if st.session_state.project_data and st.session_state.project_data.get('I0', 0) > 0:
        
        data = st.session_state.project_data
        
        st.subheader("‚úÖ D·ªØ li·ªáu D·ª± √°n ƒë√£ L·ªçc")
        col1, col2, col3 = st.columns(3)
        col4, col5, col6 = st.columns(3)

        col1.metric("V·ªën ƒê·∫ßu t∆∞ ($I_0$)", format_currency(data.get('I0')))
        col2.metric("V√≤ng ƒë·ªùi D·ª± √°n ($N$)", f"{data.get('N')} nƒÉm")
        col3.metric("WACC", f"{data.get('WACC', 0.0) * 100:.2f}%")
        col4.metric("Doanh thu ($R$)", format_currency(data.get('R')))
        col5.metric("Chi ph√≠ ($C$)", format_currency(data.get('C')))
        col6.metric("Thu·∫ø su·∫•t", f"{data.get('Tax', 0.0) * 100:.0f}%")
        
        # T√≠nh to√°n NCF ƒë·ªÉ hi·ªÉn th·ªã
        PBT = data.get('R', 0) - data.get('C', 0)
        PAT = PBT * (1 - data.get('Tax', 0.2))
        NCF = PAT
        st.session_state.project_data['NCF'] = NCF # L∆∞u NCF v√†o state

        st.metric("D√≤ng ti·ªÅn thu·∫ßn (NCF) h√†ng nƒÉm", format_currency(NCF))
        st.markdown("---")
        
        # --- 2. X√¢y d·ª±ng B·∫£ng D√≤ng ti·ªÅn v√† 3. T√≠nh Ch·ªâ s·ªë ---
        st.subheader("2 & 3. B·∫£ng D√≤ng ti·ªÅn v√† Ch·ªâ s·ªë ƒê√°nh gi√° Hi·ªáu qu·∫£")
        
        if st.button("T√≠nh to√°n Ch·ªâ s·ªë T√†i ch√≠nh (NPV, IRR, PP, DPP)"):
            st.session_state.metrics = calculate_financial_metrics(st.session_state.project_data)

        if st.session_state.metrics and st.session_state.metrics.get("CF_Table") is not None:
            metrics = st.session_state.metrics
            
            # Hi·ªÉn th·ªã Ch·ªâ s·ªë ƒê√°nh gi√°
            col_m1, col_m2, col_m3, col_m4 = st.columns(4)
            
            col_m1.metric("NPV (Gi√° tr·ªã hi·ªán t·∫°i thu·∫ßn)", format_currency(metrics['NPV']))
            col_m2.metric("IRR (T·ª∑ su·∫•t sinh l·ªùi n·ªôi b·ªô)", f"{metrics['IRR'] * 100:.2f}%" if not math.isnan(metrics['IRR']) else "N/A")
            col_m3.metric("PP (Ho√†n v·ªën)", f"{metrics['PP']:.2f} nƒÉm" if not math.isnan(metrics['PP']) else "N/A")
            col_m4.metric("DPP (Ho√†n v·ªën chi·∫øt kh·∫•u)", f"{metrics['DPP']:.2f} nƒÉm" if not math.isnan(metrics['DPP']) else "N/A")

            st.markdown("#### B·∫£ng D√≤ng ti·ªÅn D·ª± √°n")
            cf_df = metrics['CF_Table'].copy()
            
            # ƒê·ªãnh d·∫°ng DataFrame ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp h∆°n
            cf_df['NƒÉm'] = cf_df['NƒÉm'].astype(int)
            st.dataframe(
                cf_df.style.format({
                    'NCF': lambda x: format_currency(x) if x != 0 else "-",
                    'PV_NCF': lambda x: format_currency(x) if x != 0 else "-",
                    'CF_Cum': lambda x: format_currency(x) if x != 0 else "-",
                    'PV_CF_Cum': lambda x: format_currency(x) if x != 0 else "-",
                }),
                use_container_width=True,
                hide_index=True
            )
            st.markdown("---")
            
            # --- 4. Y√™u c·∫ßu AI Ph√¢n t√≠ch ---
            st.subheader("4. B√°o c√°o Ph√¢n t√≠ch Chuy√™n s√¢u (AI)")
            
            if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch Hi·ªáu qu·∫£ D·ª± √°n"):
                report = get_ai_analysis_report(metrics, st.session_state.project_data)
                st.markdown("#### K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI")
                st.info(report)
        
        else:
             st.info("Nh·∫•n n√∫t 'T√≠nh to√°n Ch·ªâ s·ªë T√†i ch√≠nh' ƒë·ªÉ t·∫°o b·∫£ng d√≤ng ti·ªÅn v√† c√°c ch·ªâ s·ªë.")

    else:
        if uploaded_file and st.session_state.doc_text and not st.session_state.project_data:
             st.warning("Vui l√≤ng nh·∫•n n√∫t 'L·ªçc D·ªØ li·ªáu T√†i ch√≠nh (AI)' ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng s·ªë.")
        elif uploaded_file and st.session_state.project_data:
             st.warning("Kh√¥ng th·ªÉ t√≠nh to√°n: D·ªØ li·ªáu ch∆∞a ƒë·ªß ho·∫∑c V·ªën ƒê·∫ßu t∆∞/V√≤ng ƒë·ªùi d·ª± √°n b·∫±ng 0.")

else:
    st.info("Vui l√≤ng t·∫£i l√™n file Word ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
